<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Yu-shui">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Yu-shui">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yu-shui">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Yu-shui</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
    <a href="https://github.com/Yu-shui" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yu-shui</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>
            
            日程表
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/15/朴素贝叶斯/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/15/朴素贝叶斯/" itemprop="url">朴素贝叶斯</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-15T00:40:20+08:00">
                2019-04-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h1><blockquote>
<p>朴素贝叶斯法（Naive Bayes）是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入 <em>x</em>x ，利用贝叶斯定理求出后验概率最大的输出 <em>y</em>y 。</p>
</blockquote>
<p> 可能读完上面这段话仍旧没办法理解朴素贝叶斯法到底是什么，又是怎样进行分类的。下面我尽可能详细且直观地描述朴素贝叶斯法的工作原理。首先我们需要知道的是，<strong>朴素贝叶斯是基于概率论的分类算法</strong>。</p>
<h3 id="1-朴素贝叶斯"><a href="#1-朴素贝叶斯" class="headerlink" title="1. 朴素贝叶斯"></a>1. 朴素贝叶斯</h3><pre><code>朴素贝叶斯被认为是最简单的分类算法之一。首先，我们需要了解一些概率论的基本理论。假设有两个随机变量X和Y，他们分别可以取值为x和y。有这两个随机变量，我们可以定义两种概率：
关键概念：联合概率与条件概率
联合概率：“X取值为x”和“Y取值为y”两个事件同时发生的概率，表示为P(X=x,Y=y)P(X=x,Y=y)      P(X = x, Y = y)P(X=x,Y=y)
条件概率：在X取值为x的前提下，Y取值为y的概率，表示为P(Y=y∣X=x)P(Y=y∣X=x)      P(Y = y | X = x)P(Y=y∣X=x)

在概率论中，我们可以证明，两个事件的联合概率等于这两个事件任意条件概率 * 这个条件事件本身的概率。
P(X=1,Y=1)=P(Y=1∣X=1)∗P(X=1)=P(X=1∣Y=1)∗P(Y=1)P(X=1,Y=1)=P(Y=1∣X=1)∗P(X=1)=P(X=1∣Y=1)∗P(Y=1)      P(X = 1, Y = 1) =P(Y = 1|X = 1)*P(X=1)=P(X = 1|Y=1)*P(Y=1)P(X=1,Y=1)=P(Y=1∣X=1)∗P(X=1)=P(X=1∣Y=1)∗P(Y=1)
简单一些，则可以将上面的式子写成：
P(X,Y)=P(Y∣X)∗P(X)=P(X∣Y)∗P(Y)P(X,Y)=P(Y∣X)∗P(X)=P(X∣Y)∗P(Y)      P(X, Y)=P(Y|X)*P(X)=P(X|Y)*P(Y)P(X,Y)=P(Y∣X)∗P(X)=P(X∣Y)∗P(Y)
由上面的式子，我们可以得到贝叶斯理论等式：
P(Y∣X)=P(X∣Y)∗P(Y)P(X)P(Y∣X)=P(X∣Y)∗P(Y)P(X)      P(Y|X) =  \frac{P(X|Y)*P(Y)}{P(X)}P(Y∣X)=P(X)P(X∣Y)∗P(Y)
而这个式子，就是我们一切贝叶斯算法的根源理论。我们可以把我们的特征XX      XX当成是我们的条件事件，而我们要求解的标签YY      YY当成是我们被满足条件后会被影响的结果，而两者之间的概率关系就是P(Y∣X)P(Y∣X)      P(Y|X)P(Y∣X)，这个概率在机器学习中，被我们称之为是标签的后验概率（posterior probability），即是说我们先知道了条件，再去求解结果。而标签 在没有任何条件限制下取值为某个值的概率，被我们写作P(Y)P(Y)      P(Y)P(Y)，与后验概率相反，这是完全没有任何条件限制的，标签的先验概率（prior probability）。而我们的P(X∣Y)P(X∣Y)      P(X|Y)P(X∣Y) 被称为“类的条件概率”，表示当Y的取值固定的时候，X为某个值的概率。
</code></pre><h3 id="3-朴素贝叶斯公式的推导"><a href="#3-朴素贝叶斯公式的推导" class="headerlink" title="3.朴素贝叶斯公式的推导"></a>3.朴素贝叶斯公式的推导</h3><p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\pp2.PNG" alt=""></p>
<h3 id="2-贝叶斯估计"><a href="#2-贝叶斯估计" class="headerlink" title="2.贝叶斯估计"></a>2.贝叶斯估计</h3><p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\pp3.PNG" alt=""></p>
<h3 id="3-朴素贝叶斯算法的过程"><a href="#3-朴素贝叶斯算法的过程" class="headerlink" title="3.朴素贝叶斯算法的过程"></a>3.朴素贝叶斯算法的过程</h3><p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\pp4.PNG" alt=""></p>
<h2 id="使用朴素贝叶斯进行文本分类示例"><a href="#使用朴素贝叶斯进行文本分类示例" class="headerlink" title="使用朴素贝叶斯进行文本分类示例"></a>使用朴素贝叶斯进行文本分类示例</h2><p>本次使用的数据集来自于业内著名的20 Newsgroups 数据集，包含20类标注好的样本，数据量共计约2万条记录。该数据集每篇文档均不长，即使同时使用多个类目数据合并起来进行建模，在单机上也可快速完成，因此具有很好的学习训练价值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from time import time</span><br><span class="line">from sklearn.datasets import load_files</span><br><span class="line"></span><br><span class="line">#加载数据</span><br><span class="line">print(&quot;loading train dataset.....&quot;)</span><br><span class="line">t=time()</span><br><span class="line">news_train=load_files(&apos;D:/20news/20news-bydate-train/&apos;)</span><br><span class="line">print(&quot;summary:&#123;0&#125; documents in &#123;1&#125; categories.&quot;.format(len(news_train.data),len(news_train.target_names)))</span><br><span class="line">print(&quot;done in &#123;0&#125; seconds&quot;.format(time()-t))</span><br></pre></td></tr></table></figure>
<p>结果输出:</p>
<p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\结果1.PNG" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#将文档转化为TF-IDF形式</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line"></span><br><span class="line">print(&quot;vaectoring train dataset......&quot;)</span><br><span class="line">t=time()</span><br><span class="line">vectorsize=TfidfVectorizer(encoding=&quot;latin-1&quot;)</span><br><span class="line">X_train=vectorsize.fit_transform((d for d in news_train.data))#转换为矩阵</span><br><span class="line">print(&quot;n_sample:%d,n_features:%d&quot;% X_train.shape)</span><br><span class="line">print(&quot;number of non-zero features in sample [&#123;0&#125;]:&#123;1&#125;&quot;.format(news_train.filenames[0],X_train[0].getnnz()))#打印</span><br><span class="line">#第一篇文章名称和文章中的词语数</span><br><span class="line">print(&quot;done in &#123;0&#125; seconds&quot;.format(time()-t))</span><br></pre></td></tr></table></figure>
<p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\结果2.PNG" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#使用模块MultinomialNB训练数据集</span><br><span class="line">from sklearn.naive_bayes import MultinomialNB</span><br><span class="line"></span><br><span class="line">print(&quot;training models....&quot;.format(time()-t))</span><br><span class="line">t=time()</span><br><span class="line">y_train=news_train.target#元素大小为0到20的一维矩阵</span><br><span class="line">clf=MultinomialNB(alpha=0.0001)#拼平滑指数，过小容易造成过拟合，过大容易过拟合</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line">train_score=clf.score(X_train,y_train)</span><br><span class="line">print(&quot;train_socre :&#123;0&#125;&quot;.format(train_score))</span><br><span class="line">print(&quot;done in &#123;0&#125; seconds&quot;.format(time()-t))</span><br></pre></td></tr></table></figure>
<p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\结果3.PNG" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#加载测试集合</span><br><span class="line">print(&quot;loading test dataset.....&quot;)</span><br><span class="line">t=time()</span><br><span class="line">news_test=load_files(&quot;D:/20news/20news-bydate-test/&quot;)</span><br><span class="line">print(&quot;summary :&#123;0&#125; Documents in &#123;1&#125; catelogies.&quot;.format(len(news_test.data),len(news_test.target_names)))</span><br><span class="line">print(&quot;done in &#123;0&#125; seconds &quot;.format(time()-t))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">      </span><br><span class="line">      #将测试集向量化</span><br><span class="line">print(&quot;向量化测试机集&quot;)</span><br><span class="line">y_test=news_test.target</span><br><span class="line">X_test=vectorsize.transform((b for b in news_test.data))</span><br><span class="line">print(&quot;n_samples: %d. n_fetures : %d &quot;% X_test.shape)</span><br><span class="line">print(&quot;&#123;0&#125; numers of None-zero in file[&#123;1&#125;]&quot;.format(X_test[0].getnnz(),news_test.filenames[0]))</span><br><span class="line">print(&quot;done in %fs&quot;%(time()-t))</span><br></pre></td></tr></table></figure>
<p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\结果4.PNG" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#取第一篇预测一下</span><br><span class="line">pred=clf.predict(X_test[0])</span><br><span class="line"></span><br><span class="line">#print(X_test[0])</span><br><span class="line">print(&quot;the first page is &#123;0&#125;,the predict is &#123;1&#125;&quot;.format(news_test.filenames[0],news_test.target_names[news_test.target[0]]))</span><br><span class="line">#模型评价</span><br><span class="line">#首先对测试机进行预测</span><br><span class="line">print(&quot;predicting the test.......&quot;)</span><br><span class="line">t0=time()</span><br><span class="line">pred=clf.predict(X_test)</span><br><span class="line">print(&quot;done in &#123;0&#125; seconds&quot;.format(time()-t0))</span><br><span class="line">#使用classification_report查看每个类别预测的准确性</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">print(&quot;classification_report on test set for classifier:&quot;)</span><br><span class="line">print(clf)</span><br><span class="line">print(classification_report(y_test,pred,target_names=news_test.target_names))#精确度，召回率，F1值</span><br><span class="line"></span><br><span class="line">print(&quot;**********************************************&quot;)</span><br><span class="line">#使用confusion_matrix生成混淆矩阵,</span><br><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">cm=confusion_matrix(y_test,pred)</span><br><span class="line">print(&quot;confusion_matrix:&quot;)</span><br><span class="line">print(cm)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/04/15/朴素贝叶斯/C:/blog\source\_posts\朴素贝叶斯\结果5.PNG" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/14/自然语言处理4-文本分析/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/14/自然语言处理4-文本分析/" itemprop="url">自然语言处理4:文本分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-14T14:13:39+08:00">
                2019-04-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="自然语言处理-4-文本表示"><a href="#自然语言处理-4-文本表示" class="headerlink" title="自然语言处理(4):文本表示"></a>自然语言处理(4):文本表示</h1><h3 id="1-TF-IDF原理"><a href="#1-TF-IDF原理" class="headerlink" title="1.TF-IDF原理"></a>1.TF-IDF原理</h3><ol>
<li><strong> 词频TF（item frequency）</strong>：某一给定词语在该文本中出现次数。该数字通常会被归一化（分子一般小于分母），以防止它偏向长的文件，因为不管该词语重要与否，它在长文件中出现的次数很可能比在段文件中出现的次数更大。       需要注意的是有一些通用词对文章主题没有太大作用，如“的”“是”等，而有一些频率出现少的词如一些专业词更能表现文章主题，所以为词语设置权重，权重的设计满足：一个词预测主题的能力越强，权重越大，反之，权重越小。也就是说，一些词只在很少几篇文章中出现，那么这样的词对文章主题的判断能力很大，这些词的权重应该设计的较大。IDF完成这样的工作。       </li>
<li><strong>逆向文件频率IDF（inverse document frequency）</strong>：一个词语普遍重要性的度量。主要思想是：如果包含词条t的文档越少, IDF越大，则说明词条具有很好的类别区分能力。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TF=(某个词在文章中出现的次数)/(文章的总词数)</span><br><span class="line">IDF=log((语料库的文档总数)/(包含该词的文档数+1))</span><br></pre></td></tr></table></figure>
<h3 id="2-使用不同的方法来计算TF-IDF的值"><a href="#2-使用不同的方法来计算TF-IDF的值" class="headerlink" title="2.使用不同的方法来计算TF-IDF的值"></a>2.使用不同的方法来计算TF-IDF的值</h3><ol>
<li>词袋模型<br>Bag of words，也叫做“词袋”，在信息检索中，Bag of words model假定对于一个文本，忽略其词序和语法，句法，将其仅仅看做是一个词集合，或者说是词的一个组合，文本中每个词的出现都是独立的，不依赖于其他词是否出现，或者说当这篇文章的作者在任意一个位置选择一个词汇都不受前面句子的影响而独立选择的。</li>
</ol>
<h5 id="1-使用gensim模块"><a href="#1-使用gensim模块" class="headerlink" title="1.使用gensim模块"></a>1.使用gensim模块</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">corpus = [</span><br><span class="line">    &apos;this is the first document&apos;,</span><br><span class="line">    &apos;this is the second second document&apos;,</span><br><span class="line">    &apos;and the third one&apos;,</span><br><span class="line">    &apos;is this the first document&apos;</span><br><span class="line">]#语料库</span><br><span class="line"></span><br><span class="line">#先做分词处理</span><br><span class="line">word_list=[]</span><br><span class="line">for i in range(len(corpus)):</span><br><span class="line">    word_list.append(corpus[i].split(&apos; &apos;))</span><br><span class="line">print(word_list)</span><br><span class="line"></span><br><span class="line">#得到每个词的id值和词频</span><br><span class="line"></span><br><span class="line">from gensim import corpora</span><br><span class="line">dic=corpora.Dictionary(word_list)#赋给语料库中每个不重复的词一个id</span><br><span class="line">new_corpus=[dic.doc2bow(text) for text in word_list]#寻找整篇语料的词典、所有词，corpora.Dictionary</span><br><span class="line">print(new_corpus)</span><br><span class="line"></span><br><span class="line">#训练gensim模型</span><br><span class="line">from gensim import models</span><br><span class="line">tfidf=models.TfidfModel(new_corpus)</span><br><span class="line">tfidf.save(&quot;my_model.tfidf&quot;)</span><br><span class="line"></span><br><span class="line">#载入模型</span><br><span class="line">tfidf=models.TfidfModel.load(&quot;my_model.tfidf&quot;)</span><br><span class="line">#使用模型得到单词的tfidf值</span><br><span class="line">tfidf_vec=[]</span><br><span class="line">for i in range(len(corpus)):</span><br><span class="line">    string=corpus[i]</span><br><span class="line">    string_bow=dic.doc2bow(string.lower().split())</span><br><span class="line">    stringtfidf=tfidf[string_bow]</span><br><span class="line">    tfidf_vec.append(stringtfidf)</span><br><span class="line">print(tfidf_vec)</span><br></pre></td></tr></table></figure>
<ol>
<li>结论</li>
</ol>
<ul>
<li>gensim训练出来的tf-idf值左边是词的id，右边是词的tfidf值</li>
<li>gensim有自动去除停用词的功能，比如the</li>
<li>gensim会自动去除单个字母，比如i</li>
<li>gensim会去除没有被训练到的词，比如name<br>所以通过gensim并不能计算每个单词的tfidf值</li>
</ul>
<h5 id="2-使用sklearn提取文本tfidf特征"><a href="#2-使用sklearn提取文本tfidf特征" class="headerlink" title="2.使用sklearn提取文本tfidf特征"></a>2.使用sklearn提取文本tfidf特征</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">tfidf_vec=TfidfVectorizer()#模型构建</span><br><span class="line">tfidf_matrix=tfidf_vec.fit_transform(corpus)#传入句子组成的list</span><br><span class="line"></span><br><span class="line">print(tfidf_vec.get_feature_names())#得到所有不重复的词</span><br><span class="line">print(tfidf_vec.vocabulary_)#得到对应的id值</span><br><span class="line">print(tfidf_matrix.toarray())</span><br></pre></td></tr></table></figure>
<h6 id="3-python提取文本特征tfidf值"><a href="#3-python提取文本特征tfidf值" class="headerlink" title="3.python提取文本特征tfidf值"></a>3.python提取文本特征tfidf值</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#统计词频</span><br><span class="line">from collections import Counter</span><br><span class="line">countlist=[]</span><br><span class="line">for i in range(len(word_list)):</span><br><span class="line">    count=Counter(word_list[i])#每个count是一个句子</span><br><span class="line">    countlist.append(count)</span><br><span class="line"># word可以通过count得到，count可以通过countlist得到</span><br><span class="line"># count[word]可以得到每个单词的词频， sum(count.values())得到整个句子的单词总数</span><br><span class="line">def tf(word,count):</span><br><span class="line">    return count[word]/sum(count.values())</span><br><span class="line">#统计含有该单词的句子数</span><br><span class="line">def n_containing(word,countlist):</span><br><span class="line">    return sum(1 for count in countlist if word in count)</span><br><span class="line"># len(count_list)是指句子的总数，n_containing(word, count_list)是指含有该单词的句子的总数，加1是为了防止分母为0</span><br><span class="line">def idf(word, count_list):</span><br><span class="line">    return math.log(len(count_list) / (1 + n_containing(word, count_list)))</span><br><span class="line"></span><br><span class="line"># 将tf和idf相乘</span><br><span class="line">def tfidf(word, count, count_list):</span><br><span class="line">    return tf(word, count) * idf(word, count_list)</span><br><span class="line"></span><br><span class="line">import math</span><br><span class="line">for i,count in enumerate(countlist):</span><br><span class="line">    print(&quot;Top words in docment&#123;&#125;&quot;.format(i+1))</span><br><span class="line">    scores=&#123;word:tfidf(word,count,countlist) for word in count&#125;</span><br><span class="line">    sorted_words=sorted(scores.items(),key=lambda x:x[1],reverse=True)</span><br><span class="line">    for word,score in sorted_words[:]:</span><br><span class="line">        print(&quot;\tWord: &#123;&#125;, TF-IDF: &#123;&#125;&quot;.format(word, round(score, 5)))</span><br></pre></td></tr></table></figure>
<h3 id="3-sklearn：点互信息和互信息"><a href="#3-sklearn：点互信息和互信息" class="headerlink" title="3.sklearn：点互信息和互信息"></a>3.sklearn：点互信息和互信息</h3><ol>
<li>点互信息PMI<br>机器学习相关文献里面，经常会用到点互信息PMI(Pointwise Mutual Information)这个指标来衡量两个事物之间的相关性（比如两个词）。<br>  在概率论中，我们知道，如果x跟y不相关，则p(x,y)=p(x)p(y)。二者相关性越大，则p(x, y)就相比于p(x)p(y)越大。用后面的式子可能更好理解，在y出现的情况下x出现的条件概率p(x|y)除以x本身出现的概率p(x)，自然就表示x跟y的相关程度。举个自然语言处理中的例子来说，我们想衡量like这个词的极性（正向情感还是负向情感）。我们可以预先挑选一些正向情感的词，比如good。然后我们算like跟good的PMI。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PMI(x;y)=log(p(x,y)/(p(x)*p(y)))=log(p(y|x)/p(y))</span><br></pre></td></tr></table></figure>
<ol>
<li>互信息MI<br>衡量的是两个随机变量之间的相关性，即一个随机变量中包含的关于另一个随机变量的信息量。所谓的随机变量，即随机试验结果的量的表示，可以简单理解为按照一个概率分布进行取值的变量，比如随机抽查的一个人的身高就是一个随机变量。可以看出，互信息其实就是对X和Y的所有可能的取值情况的点互信息PMI的加权和。因此，点互信息这个名字还是很形象的。</li>
</ol>
<h3 id="4-如何进行特征选择（理论篇）机器学习你会遇到的“坑”-来源于网络"><a href="#4-如何进行特征选择（理论篇）机器学习你会遇到的“坑”-来源于网络" class="headerlink" title="4.如何进行特征选择（理论篇）机器学习你会遇到的“坑”(来源于网络)"></a>4.如何进行特征选择（理论篇）机器学习你会遇到的“坑”(来源于网络)</h3><p>一个典型的机器学习任务，是通过样本的特征来预测样本所对应的值。如果样本的特征少了，我们会考虑增加特征，比如Polynomial Regression就是典型的增加特征的算法。在前一周的课程中，相信大家已经体会到，模型特征越多，模型的复杂度也就越高，越容易导致过拟合。事实上，如果我们的样本数少于特征数，那么过拟合就不可避免。</p>
<p>而现实中的情况，往往是特征太多了，需要减少一些特征。</p>
<p>首先是“无关特征”（irrelevant feature）。比如，通过空气的湿度，环境的温度，风力和当地人的男女比例来预测明天会不会下雨，其中男女比例就是典型的无关特征。</p>
<p>其次，要减少的另一类特征叫做“多余特征”（redundant feature），比如，通过房屋的面积，卧室的面积，车库的面积，所在城市的消费水平，所在城市的税收水平等特征来预测房价，那么消费水平（或税收水平）就是多余特征。证据表明，消费水平和税收水平存在相关性，我们只需要其中一个特征就够了，因为另一个能从其中一个推演出来。（如果是线性相关，那么我们在用线性模型做回归的时候，会出现严重的多重共线性问题，将会导致过拟合。）</p>
<p>减少特征有非常重要的现实意义，甚至有人说，这是工业界最重要的问题。因为除了降低过拟合，特征选择还可以使模型获得更好的解释性，加快模型的训练速度，一般的，还会获得更好的性能。</p>
<p>问题在于，在面对未知领域的时候，很难有足够的知识去判断特征与我们的目标是不是相关，特征与特征之间是不是相关。这时候，就需要一些数学和工程上的办法来帮助我们尽可能地把恰好需要的特征选择出来。</p>
<p>常见的方法包括过滤法（Filter）、包裹法（Warpper），嵌入法</p>
<h5 id="1-过滤法"><a href="#1-过滤法" class="headerlink" title="1.过滤法"></a>1.过滤法</h5><p>过滤法只用于检验特征向量和目标（响应变量）的相关度，不需要任何的机器学习的算法，不依赖于任何模型，只是应用统计量做筛选：我们根据统计量的大小，设置合适的阈值，将低于阈值的特征剔除.</p>
<h5 id="2-包裹法"><a href="#2-包裹法" class="headerlink" title="2.包裹法"></a>2.包裹法</h5><p>与过滤法不同的是，包裹法采用的是特征搜索的办法。它的基本思路是，从初始特征集合中不断的选择子集合，根据学习器的性能来对子集进行评价，直到选择出最佳的子集。在搜索过程中，我们会对每个子集做建模和训练。</p>
<p>图为包裹法的流程图，其中Estimated Accuracy是机器学习分类问题的典型的性能指标。</p>
<p>基于此，包裹法很大程度上变成了一个计算机问题：在特征子集的搜索问题（subset search）。我们有多种思路，最容易想到的办法是穷举（Brute-force search），遍历所有可能的子集，但这样的方法适用于特征数较少的情形，特征一旦增多，就会遇到组合爆炸，在计算上并不可行。（N个特征，则子集会有种可能）</p>
<p>另一个思路是随机化搜索，比如拉斯维加斯算法（Las Vegas algorithm），但这样的算法在特征数大的时候，计算开销仍然很大，而且有给不出任何解的风险。所以，我们常使用的是贪心算法：</p>
<ul>
<li>前向搜索（Forward search）</li>
</ul>
<p>在开始时，按照特征数来划分子集，每个子集只有一个特征，对每个子集进行评价。然后在最优的子集上逐步增加特征，使模型性能提升最大，直到增加特征并不能使模型性能提升为止。</p>
<ul>
<li>后向搜索（Backward search）</li>
</ul>
<p>在开始时，将特征集合分别减去一个特征作为子集，每个子集有N—1个特征，对每个子集进行评价。然后在最优的子集上逐步减少特征，使得模型性能提升最大，直到减少特征并不能使模型性能提升为止。</p>
<ul>
<li>双向搜索（Bidirectional search）</li>
</ul>
<p>将Forward search 和Backward search结合起来。</p>
<ul>
<li>递归剔除（Recursive elimination ）</li>
</ul>
<p>反复的训练模型，并剔除每次的最优或者最差的特征，将剔除完毕的特征集进入下一轮训练，直到所有的特征被剔除，被剔除的顺序度量了特征的重要程度。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/14/自然语言处理3-文本处理技能基础/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/14/自然语言处理3-文本处理技能基础/" itemprop="url">自然语言处理3:文本处理技能基础</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-14T14:13:14+08:00">
                2019-04-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="NPL之基本文本处理技能"><a href="#NPL之基本文本处理技能" class="headerlink" title="NPL之基本文本处理技能"></a>NPL之基本文本处理技能</h1><h2 id="1-分词的概念"><a href="#1-分词的概念" class="headerlink" title="1.分词的概念"></a>1.分词的概念</h2><p>一个良好的分词系统应由词典和统计两套系统组成。后者为前者构造可持续更新的词典，识别新词，同时对消岐部分进行匹配。在分词过程中，好的词典很重要，其次算法要跟着需求走，不同需求选择不同算法，比如有些要求速度快，与兴趣相关，此时算法是次要的，而有些需求注重的是精度。</p>
<p>现有方法：基于词典的匹配：前向最大匹配，后向最大匹配；基于字的标注：最大熵模型，条件随机场模型，感知器模型；其他方法：与词性标注集合，与句法分析结合。</p>
<h2 id="2-分词最大向量化，逆向最大，双向最大匹配法"><a href="#2-分词最大向量化，逆向最大，双向最大匹配法" class="headerlink" title="2.分词最大向量化，逆向最大，双向最大匹配法"></a>2.分词最大向量化，逆向最大，双向最大匹配法</h2><h5 id="1-分词最大正向匹配法（示例来自网络）"><a href="#1-分词最大正向匹配法（示例来自网络）" class="headerlink" title="1.分词最大正向匹配法（示例来自网络）"></a>1.分词最大正向匹配法（示例来自网络）</h5><p>1、正向最大匹配法：<br>正向即从前往后取词，从7-&gt;1，每次减一个字，直到词典命中或剩下1个单字。<br>第1次：“我们在野生动物”，扫描7字词典，无<br>第2次：“我们在野生动”，扫描6字词典，无<br>。。。。<br>第6次：“我们”，扫描2字词典，有<br>扫描中止，输出第1个词为“我们”，去除第1个词后开始第2轮扫描，即：<br>第2轮扫描：<br>第1次：“在野生动物园玩”，扫描7字词典，无<br>第2次：“在野生动物园”，扫描6字词典，无<br>。。。。<br>第6次：“在野”，扫描2字词典，有<br>扫描中止，输出第2个词为“在野”，去除第2个词后开始第3轮扫描，即：<br>第3轮扫描：<br>第1次：“生动物园玩”，扫描5字词典，无<br>第2次：“生动物园”，扫描4字词典，无<br>第3次：“生动物”，扫描3字词典，无<br>第4次：“生动”，扫描2字词典，有<br>扫描中止，输出第3个词为“生动”，第4轮扫描，即：<br>第4轮扫描：<br>第1次：“物园玩”，扫描3字词典，无<br>第2次：“物园”，扫描2字词典，无<br>第3次：“物”，扫描1字词典，无<br>扫描中止，输出第4个词为“物”，非字典词数加1，开始第5轮扫描，即：<br>第5轮扫描：<br>第1次：“园玩”，扫描2字词典，无<br>第2次：“园”，扫描1字词典，有<br>扫描中止，输出第5个词为“园”，单字字典词数加1，开始第6轮扫描，即：<br>第6轮扫描：<br>第1次：“玩”，扫描1字字典词，有<br>扫描中止，输出第6个词为“玩”，单字字典词数加1，整体扫描结束。<br>正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，单字字典词为2，非词典词为1。</p>
<h5 id="2-逆向最大匹配法"><a href="#2-逆向最大匹配法" class="headerlink" title="2.逆向最大匹配法"></a>2.逆向最大匹配法</h5><p>逆向即从后往前取词，其他逻辑和正向相同。即：<br>第1轮扫描：“在野生动物园玩”<br>第1次：“在野生动物园玩”，扫描7字词典，无<br>第2次：“野生动物园玩”，扫描6字词典，无<br>。。。。<br>第7次：“玩”，扫描1字词典，有<br>扫描中止，输出“玩”，单字字典词加1，开始第2轮扫描<br>第2轮扫描：“们在野生动物园”<br>第1次：“们在野生动物园”，扫描7字词典，无<br>第2次：“在野生动物园”，扫描6字词典，无<br>第3次：“野生动物园”，扫描5字词典，有<br>扫描中止，输出“野生动物园”，开始第3轮扫描<br>第3轮扫描：“我们在”<br>第1次：“我们在”，扫描3字词典，无<br>第2次：“们在”，扫描2字词典，无<br>第3次：“在”，扫描1字词典，有<br>扫描中止，输出“在”，单字字典词加1，开始第4轮扫描<br>第4轮扫描：“我们”<br>第1次：“我们”，扫描2字词典，有<br>扫描中止，输出“我们”，整体扫描结束。<br>逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，单字字典词为2，非词典词为0。</p>
<h5 id="3-双向最大匹配法"><a href="#3-双向最大匹配法" class="headerlink" title="3.双向最大匹配法"></a>3.双向最大匹配法</h5><p>正向最大匹配法和逆向最大匹配法，都有其局限性(如：长春药店，逆向切分为“长/春药店”），因此有人又提出了双向最大匹配法，双向最大匹配法。即，两种算法都切一遍，然后根据大颗粒度词越多越好，非词典词和单字词越少越好的原则，选取其中一种分词结果输出。<br>如：“我们在野生动物园玩”<br>正向最大匹配法，最终切分结果为：“我们/在野/生动/物/园/玩”，其中，两字词3个，单字字典词为2，非词典词为1。<br>逆向最大匹配法，最终切分结果为：“我们/在/野生动物园/玩”，其中，五字词1个，两字词1个，单字字典词为2，非词典词为0。<br>非字典词：正向(1)&gt;逆向(0)（越少越好）<br>单字字典词：正向(2)=逆向(2)（越少越好）<br>总词数：正向(6)&gt;逆向(4)（越少越好）<br>因此最终输出为逆向结果。</p>
<h2 id="2-Python标准库——collections模块的Counter类"><a href="#2-Python标准库——collections模块的Counter类" class="headerlink" title="2.Python标准库——collections模块的Counter类"></a>2.Python标准库——collections模块的Counter类</h2><p>Counter类的目的是用来跟踪值出现的次数。它是一个无序的容器类型，以字典的键值对形式存储，其中元素作为key，其计数作为value。计数值可以是任意的Interger（包括0和负数）</p>
<h6 id="1-创建"><a href="#1-创建" class="headerlink" title="1.创建"></a>1.创建</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c = Counter()  # 创建一个空的Counter类</span><br><span class="line">&gt;&gt;&gt; c = Counter(&apos;gallahad&apos;)  # 从一个可iterable对象（list、tuple、dict、字符串等）创建</span><br><span class="line">&gt;&gt;&gt; c = Counter(&#123;&apos;a&apos;: 4, &apos;b&apos;: 2&#125;)  # 从一个字典对象创建</span><br><span class="line">&gt;&gt;&gt; c = Counter(a=4, b=2)  # 从一组键值对创建</span><br></pre></td></tr></table></figure>
<h6 id="2-2-计数值的访问与缺失的键"><a href="#2-2-计数值的访问与缺失的键" class="headerlink" title="2.2 计数值的访问与缺失的键"></a>2.2 计数值的访问与缺失的键</h6><p>当所访问的键不存在时，返回0，而不是KeyError；否则返回它的计数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c = Counter(&quot;abcdefgab&quot;)</span><br><span class="line">&gt;&gt;&gt; c[&quot;a&quot;]</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; c[&quot;c&quot;]</span><br><span class="line">1</span><br><span class="line">&gt;&gt;&gt; c[&quot;h&quot;]</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<h5 id="3-计数器的更新（update和subtract）"><a href="#3-计数器的更新（update和subtract）" class="headerlink" title="3. 计数器的更新（update和subtract）"></a>3. 计数器的更新（update和subtract）</h5><p>可以使用一个iterable对象或者另一个Counter对象来更新键值。<br>计数器的更新包括增加和减少两种。其中，增加使用update()方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c = Counter(&apos;which&apos;)</span><br><span class="line">&gt;&gt;&gt; c.update(&apos;witch&apos;)  # 使用另一个iterable对象更新</span><br><span class="line">&gt;&gt;&gt; c[&apos;h&apos;]</span><br><span class="line">3</span><br><span class="line">&gt;&gt;&gt; d = Counter(&apos;watch&apos;)</span><br><span class="line">&gt;&gt;&gt; c.update(d)  # 使用另一个Counter对象更新</span><br><span class="line">&gt;&gt;&gt; c[&apos;h&apos;]</span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h5 id="4-元素的删除"><a href="#4-元素的删除" class="headerlink" title="4.元素的删除"></a>4.元素的删除</h5><p>删除元素使用del</p>
<h5 id="5-elements"><a href="#5-elements" class="headerlink" title="5 elements()"></a>5 elements()</h5><p>返回一个迭代器。元素被重复了多少次，在该迭代器中就包含多少个该元素。元素排列无确定顺序，个数小于1的元素不被包含。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c = Counter(a=4, b=2, c=0, d=-2)</span><br><span class="line">&gt;&gt;&gt; list(c.elements())</span><br><span class="line">[&apos;a&apos;, &apos;a&apos;, &apos;a&apos;, &apos;a&apos;, &apos;b&apos;, &apos;b&apos;]</span><br></pre></td></tr></table></figure>
<h5 id="6-most-common-n"><a href="#6-most-common-n" class="headerlink" title="6.most_common([n])"></a>6.most_common([n])</h5><p>返回一个TopN列表。如果n没有被指定，则返回所有元素。当多个元素计数值相同时，排列是无确定顺序的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; c = Counter(&apos;abracadabra&apos;)</span><br><span class="line">&gt;&gt;&gt; c.most_common()</span><br><span class="line">[(&apos;a&apos;, 5), (&apos;r&apos;, 2), (&apos;b&apos;, 2), (&apos;c&apos;, 1), (&apos;d&apos;, 1)]</span><br><span class="line">&gt;&gt;&gt; c.most_common(3)</span><br><span class="line">[(&apos;a&apos;, 5), (&apos;r&apos;, 2), (&apos;b&apos;, 2)]</span><br></pre></td></tr></table></figure>
<h5 id="7-常规操作"><a href="#7-常规操作" class="headerlink" title="7.常规操作"></a>7.常规操作</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sum(c.values())  # 所有计数的总数</span><br><span class="line">c.clear()  # 重置Counter对象，注意不是删除</span><br><span class="line">list(c)  # 将c中的键转为列表</span><br><span class="line">set(c)  # 将c中的键转为set</span><br><span class="line">dict(c)  # 将c中的键值对转为字典</span><br><span class="line">c.items()  # 转为(elem, cnt)格式的列表</span><br><span class="line">Counter(dict(list_of_pairs))  # 从(elem, cnt)格式的列表转换为Counter类对象</span><br><span class="line">c.most_common()[:-n:-1]  # 取出计数最少的n-1个元素</span><br><span class="line">c += Counter()  # 移除0和负值</span><br></pre></td></tr></table></figure>
<h2 id="3-语言模型中unigram、bigram、trigram的概念"><a href="#3-语言模型中unigram、bigram、trigram的概念" class="headerlink" title="3.语言模型中unigram、bigram、trigram的概念"></a>3.语言模型中unigram、bigram、trigram的概念</h2><ol>
<li>unigram 一元分词，把句子分成一个一个的汉字</li>
<li>bigram 二元分词，把句子从头到尾每两个字组成一个词语</li>
<li>trigram 三元分词，把句子从头到尾每三个字组成一个词语.</li>
</ol>
<h5 id="n-gram模型的概念"><a href="#n-gram模型的概念" class="headerlink" title="n-gram模型的概念"></a>n-gram模型的概念</h5><p>n-gram模型也称为n-1阶马尔科夫模型，它有一个有限历史假设：当前词的出现概率仅仅与前面n-1个词相关。因此(1)式可以近似为：</p>
<p>当n取1、2、3时，n-gram模型分别称为unigram、bigram和trigram语言模型。n-gram模型的参数就是条件概率</p>
<p>假设词表的大小为100,000，那么n-gram模型的参数数量为</p>
<p>n越大，模型越准确，也越复杂，需要的计算量越大。最常用的是bigram，其次是unigram和trigram，n取≥4的情况较少。</p>
<h2 id="4-文本矩阵化-要求采用结巴分词来进行分词操作"><a href="#4-文本矩阵化-要求采用结巴分词来进行分词操作" class="headerlink" title="4.文本矩阵化(要求采用结巴分词来进行分词操作)"></a>4.文本矩阵化(要求采用结巴分词来进行分词操作)</h2><p>分词（可采用结巴分词来进行分词操作，其他库也可以）；去停用词；构造词表。<br>每篇文档的向量化。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import jieba</span><br><span class="line">import re</span><br><span class="line">stopwords = &#123;&#125;</span><br><span class="line">fstop = open(&apos;stop_words.txt&apos;, &apos;r&apos;,encoding=&apos;utf-8&apos;,errors=&apos;ingnore&apos;)</span><br><span class="line">for eachWord in fstop:</span><br><span class="line">    stopwords[eachWord.strip()] = eachWord.strip()  #停用词典</span><br><span class="line">fstop.close()</span><br><span class="line">f1=open(&apos;tt1.txt&apos;,&apos;r&apos;,encoding=&apos;utf-8&apos;,errors=&apos;ignore&apos;)</span><br><span class="line">f2=open(&apos;fenci.txt&apos;,&apos;w&apos;,encoding=&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">line=f1.readline()</span><br><span class="line">while line:</span><br><span class="line">    line = line.strip()  #去前后的空格</span><br><span class="line">    line = re.sub(r&quot;[0-9\s+\.\!\/_,$%^*()?;；:-【】+\&quot;\&apos;]+|[+——！，;:。？、~@#￥%……&amp;*（）]+&quot;, &quot; &quot;, line) #去标点符号</span><br><span class="line">    seg_list=jieba.cut(line,cut_all=False)  #结巴分词</span><br><span class="line">    outStr=&quot;&quot;</span><br><span class="line">    for word in seg_list:</span><br><span class="line">        if word not in stopwords:</span><br><span class="line">            outStr+=word</span><br><span class="line">            outStr+=&quot; &quot;</span><br><span class="line">    f2.write(outStr)</span><br><span class="line">    line=f1.readline()</span><br><span class="line">f1.close()</span><br><span class="line">f2.close()</span><br></pre></td></tr></table></figure>
<p>##### </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/09/tensorflow-及机器学习基础知识/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/09/tensorflow-及机器学习基础知识/" itemprop="url">tensorflow 及机器学习基础知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-09T14:03:45+08:00">
                2019-04-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-召回率和查全率"><a href="#1-召回率和查全率" class="headerlink" title="1.召回率和查全率"></a>1.召回率和查全率</h2><p>召回率(Recall Rate,也叫查全率，是检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率，精度是检索出的相关文档数与检索出的文档总数的比率，衡量的是检索系统查准率。</p>
<p>召回率(Recall)和精度(Precise)是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。</p>
<h2 id="1-ROC曲线"><a href="#1-ROC曲线" class="headerlink" title="1.ROC曲线"></a>1.ROC曲线</h2><p>1、roc曲线：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。</p>
<p><strong>横轴</strong>：负正类率(false postive rate FPR)特异度，划分实例中所有负例占所有负例的比例；(1-Specificity)</p>
<p><strong>纵轴</strong>：真正类率(true postive rate TPR)灵敏度，Sensitivity(正类覆盖率)</p>
<p>机器学习中常用的指标量</p>
<p><strong>TP</strong>:正确的肯定数目</p>
<p><strong>FN</strong>:漏报，没有找到正确匹配的数目</p>
<p><strong>FP</strong>:误报，没有的匹配不正确</p>
<p><strong>TN</strong>:正确拒绝的非匹配数目</p>
<p>由上表可得出横，纵轴的计算公式：</p>
<p>(1)真正类率(True Postive Rate)TPR: <strong>TP/(TP+FN)</strong>,代表分类器预测的<strong>正类中</strong>实际正实例占所有正实例的比例。Sensitivity</p>
<p>(2)负正类率(False Postive Rate)FPR: <strong>FP/(FP+TN)</strong>，代表分类器预测的<strong>正类中</strong>实际负实例占所有负实例的比例。1-Specificity</p>
<p>(3)真负类率(True Negative Rate)TNR: <strong>TN/(FP+TN)</strong>,代表分类器预测的<strong>负类中</strong>实际负实例占所有负实例的比例，<strong>TNR=1-FPR</strong>。Specificity</p>
<p>AUC(Area under Curve)：Roc曲线下的面积，介于0.1和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。</p>
<p><strong>首先AUC值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面，从而能够更好地分类。</strong></p>
<h2 id="3-为什么使用Roc-和Auc评价分类器"><a href="#3-为什么使用Roc-和Auc评价分类器" class="headerlink" title="3. 为什么使用Roc 和Auc评价分类器"></a>3. 为什么使用Roc 和Auc评价分类器</h2><p>既然已经这么多标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。</p>
<h2 id="4-PR曲线"><a href="#4-PR曲线" class="headerlink" title="4.PR曲线"></a>4.PR曲线</h2><p>P-R曲线刻画查准率和查全率之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。<br> 即：查准率P=TP／(TP + FP) 查全率=TP／（TP+FN）<br> 查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低，例如，若希望将好瓜尽可能多选出来，则可通过增加选瓜的数量来实现，如果希望将所有的西瓜都选上，那么所有的好瓜必然都被选上了，但这样查准率就会较低；若希望选出的瓜中好瓜比例尽可能高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<p><img src="/2019/04/09/tensorflow-及机器学习基础知识/C:/blog\source\_posts\tensorflow-及机器学习基础知识\pr曲线.png" alt="PR曲线"></p>
<h2 id="5-IMDB影评数据集"><a href="#5-IMDB影评数据集" class="headerlink" title="5.IMDB影评数据集"></a>5.IMDB影评数据集</h2><p>该数据下载后包含train和test两个文件夹和三个文件，其中test文件夹中的两个文件夹pos和neg分别为1.25W个代表积极和消极态度的训练样本。而train中的三个文件夹pos、neg、unsup分别为1.25W代表积极和消极态度的训练样本以及5W个未标记的样本。未标记样本可以用来作无监督学习时使用。</p>
<h2 id="THUCnews数据集"><a href="#THUCnews数据集" class="headerlink" title="THUCnews数据集"></a>THUCnews数据集</h2><p>THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。我们在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/用skikit-learn实现决策树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/用skikit-learn实现决策树/" itemprop="url">用skikit-learn实现决策树</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T21:42:41+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="用scikit-learn实现决策树算法"><a href="#用scikit-learn实现决策树算法" class="headerlink" title="用scikit-learn实现决策树算法"></a>用scikit-learn实现决策树算法</h1><h2 id="1、scikit-learn决策树算法类库介绍"><a href="#1、scikit-learn决策树算法类库介绍" class="headerlink" title="1、scikit-learn决策树算法类库介绍"></a>1、scikit-learn决策树算法类库介绍</h2><p>​         scikit-learn决策树算法类库内部实现是使用了调优过的CART树算法，既可以做分类，又可以做回归。分类决策树的类对应的是DecisionTreeClassifier，而回归决策树的类对应的是DecisionTreeRegressor。两者的参数定义几乎完全相同，但是意义不全相同。下面就对DecisionTreeClassifier和DecisionTreeRegressor的重要参数做一个总结，重点比较两者参数使用的不同点和调参的注意点。 </p>
<h2 id="2、DecisionTreeClassifier和DecisionTreeClassifier-重要参数调参注意点"><a href="#2、DecisionTreeClassifier和DecisionTreeClassifier-重要参数调参注意点" class="headerlink" title="2、DecisionTreeClassifier和DecisionTreeClassifier 重要参数调参注意点"></a>2、DecisionTreeClassifier和DecisionTreeClassifier 重要参数调参注意点</h2><h3 id="2-1-特征选择标准criterion"><a href="#2-1-特征选择标准criterion" class="headerlink" title="2.1 特征选择标准criterion"></a>2.1 特征选择标准criterion</h3><p>​        DecisionTreeClassifier：可以使用”gini”或者”entropy”，前者代表基尼系数，后者代表信息增益。一般说使用默认的基尼系数”gini”就可以了，即CART算法。除非你更喜欢类似ID3, C4.5的最优特征选择方法。 </p>
<p>​        DecisionTreeRegressor：可以使用”mse”或者”mae”，前者是均方差，后者是和均值之差的绝对值之和。推荐使用默认的”mse”。一般来说”mse”比”mae”更加精确。除非你想比较二个参数的效果的不同之处。</p>
<h3 id="2-2-特征划分点选择标准splitter"><a href="#2-2-特征划分点选择标准splitter" class="headerlink" title="2.2 特征划分点选择标准splitter"></a>2.2 特征划分点选择标准splitter</h3><p>​        可以使用”best”或者”random”。前者在特征的所有划分点中找出最优的划分点。后者是随机的在部分划分点中找局部最优的划分点。<br>​         默认的”best”适合样本量不大的时候，而如果样本数据量非常大，此时决策树构建推荐”random” </p>
<h3 id="2-3-划分时考虑的最大特征数max-features"><a href="#2-3-划分时考虑的最大特征数max-features" class="headerlink" title="2.3 划分时考虑的最大特征数max_features"></a>2.3 划分时考虑的最大特征数max_features</h3><p>​        可以使用很多种类型的值，默认是”None”,意味着划分时考虑所有的特征数；如果是”log2”意味着划分时最多考虑log2N个特征；如果是”sqrt”或者”auto”意味着划分时最多考虑sqrt(N)个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑（百分比xN）取整后的特征数。其中N为样本总特征数。<br>​         一般来说，如果样本特征数不多，比如小于50，我们用默认的”None”就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。</p>
<h3 id="2-4-决策树最大深max-depth"><a href="#2-4-决策树最大深max-depth" class="headerlink" title="2.4 决策树最大深max_depth"></a>2.4 决策树最大深max_depth</h3><p>​        决策树的最大深度，默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。</p>
<h3 id="2-5-内部节点再划分所需最小样本数min-samples-split"><a href="#2-5-内部节点再划分所需最小样本数min-samples-split" class="headerlink" title="2.5 内部节点再划分所需最小样本数min_samples_split"></a>2.5 内部节点再划分所需最小样本数min_samples_split</h3><p>​        这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。我之前的一个项目例子，有大概10万样本，建立决策树时，我选择了min_samples_split=10。可以作为参考。</p>
<h3 id="2-6-叶子节点最少样本数min-samples-leaf"><a href="#2-6-叶子节点最少样本数min-samples-leaf" class="headerlink" title="2.6 叶子节点最少样本数min_samples_leaf"></a>2.6 叶子节点最少样本数min_samples_leaf</h3><p>​        这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1，可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。之前的10万样本项目使用min_samples_leaf的值为5，仅供参考。</p>
<h3 id="2-7-叶子节点最小的样本权重和min-weight-fraction-leaf"><a href="#2-7-叶子节点最小的样本权重和min-weight-fraction-leaf" class="headerlink" title="2.7 叶子节点最小的样本权重和min_weight_fraction_leaf"></a>2.7 叶子节点最小的样本权重和min_weight_fraction_leaf</h3><p>​        这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。 默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。</p>
<h3 id="2-8-最大叶子节点数max-leaf-nodes"><a href="#2-8-最大叶子节点数max-leaf-nodes" class="headerlink" title="2.8 最大叶子节点数max_leaf_nodes"></a>2.8 最大叶子节点数max_leaf_nodes</h3><p>​        通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。</p>
<h3 id="2-9-类别权重class-weight"><a href="#2-9-类别权重class-weight" class="headerlink" title="2.9 类别权重class_weight"></a>2.9 类别权重class_weight</h3><p>​        不适用于回归树。指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多，导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重，或者用“balanced”，如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。当然，如果你的样本类别分布没有明显的偏倚，则可以不管这个参数，选择默认的”None”</p>
<h3 id="2-10-节点划分最小不纯度min-impurity-split"><a href="#2-10-节点划分最小不纯度min-impurity-split" class="headerlink" title="2.10 节点划分最小不纯度min_impurity_split"></a>2.10 节点划分最小不纯度min_impurity_split</h3><p>​        这个值限制了决策树的增长，如果某节点的不纯度(基尼系数，信息增益，均方差，绝对差)小于这个阈值，则该节点不再生成子节点。即为叶子节点 。</p>
<h3 id="2-11-数据是否预排序presort"><a href="#2-11-数据是否预排序presort" class="headerlink" title="2.11 数据是否预排序presort"></a>2.11 数据是否预排序presort</h3><p>​        这个值是布尔值，默认是False不排序。一般来说，如果样本量少或者限制了一个深度很小的决策树，设置为true可以让划分点选择更加快，决策树建立的更加快。如果样本量太大的话，反而没有什么好处。问题是样本量少的时候，我速度本来就不慢。所以这个值一般懒得理它就可以了。</p>
<p>​        除了这些参数要注意以外，其他在调参时的注意点有：<br> 　　1）当样本少数量但是样本特征非常多的时候，决策树很容易过拟合，一般来说，样本数比特征数多一些会比较容易建立健壮的模型<br> 　　2）如果样本数量少但是样本特征非常多，在拟合决策树模型前，推荐先做维度规约，比如主成分分析（PCA），特征选择（Losso）或者独立成分分析（ICA）。这样特征的维度会大大减小。再来拟合决策树模型效果会好。<br>​     　3）推荐多用决策树的可视化（下节会讲），同时先限制决策树的深度（比如最多3层），这样可以先观察下生成的决策树里数据的初步拟合情况，然后再决定是否要增加深度。<br> 　　4）在训练模型前，注意观察样本的类别情况（主要指分类树），如果类别分布非常不均匀，就要考虑用class_weight来限制模型过于偏向样本多的类别。<br> 　　5）决策树的数组使用的是numpy的float32类型，如果训练数据不是这样的格式，算法会先做copy再运行。<br> 　　6）如果输入的样本矩阵是稀疏的，推荐在拟合前调用csc_matrix稀疏化，在预测前调用csr_matrix稀疏化</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/安装时遇到的问题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/安装时遇到的问题/" itemprop="url">安装时遇到的问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T14:39:38+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>配置 python 和 anaconda 环境，在装 jupyter notebook 时，出了点问题，搞了一天半终于搞好了，也是在 github 里找到了这个问题的解答。</p>
<p>当时显示的是无法连接到python，不知道为什么，帮他们装的notebook居然都是中文，后来发现是 no connection to kernel</p>
<p>具体操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tornado==4.5.3</span><br></pre></td></tr></table></figure>
<p>这么一个错误花了一天多。。服了。。</p>
<p>很明显，这是版本问题，现在直接 pip install jupyter notebook 时，附带安装的 tornado 是6.0版本的，而能操作的是4.5.3版本的（掀桌）。。。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/tensorflow-gpu配置/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/tensorflow-gpu配置/" itemprop="url">tensorflow-gpu配置</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T14:38:32+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>越来越多的的人入坑机器学习，深度学习，tensorflow 作为目前十分流行又强大的一个框架，自然会有越来越多的新人（我也刚入门）准备使用，一般装的都是 CPU 版的 tensorflow，然而使用 GPU 跑 tensorflow，速度可以快上好几倍。正好前段时间看到了使用小米pro（我目前使用的笔记本，感觉贼好用（我没有在推销））配置 gpu 的教程，就试了试，最后成功了。</p>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>操作系统：Windows10</p>
<p>配置：<strong>Tensorflow 1.12 + CUDA 9.0 +cuDNN v7.1 for CUDA9.0</strong></p>
<p>GPU：NVIDIA GeForce MX150（小米pro i7-8550 8G 256G）</p>
<p>软件：Anaconda</p>
<p><em>注：发现 tensorflow 1.13 发布了，但其配置要求与1.12版本有所差别，若按照本博客配置1.13版本运行会报错（可能与cuda版本相关，据说1.13版本支持cuda10了，可以试试cuda10）。         2019/3/2</em></p>
<h1 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h1><h2 id="一、安装CUDA、cuDNN"><a href="#一、安装CUDA、cuDNN" class="headerlink" title="一、安装CUDA、cuDNN"></a>一、安装CUDA、cuDNN</h2><h3 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h3><p>关于 CUDA 的安装，看这篇<a href="https://blog.csdn.net/XCCCCZ/article/details/80385448" target="_blank" rel="noopener">文章</a>，写的很详细（好吧，还是我比较懒，不太想敲键盘）</p>
<h3 id="cuDNN"><a href="#cuDNN" class="headerlink" title="cuDNN"></a>cuDNN</h3><p>官网<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">下载地址</a></p>
<p><strong>注意：下载的时候要下对应自己下载的CUDA的版本</strong></p>
<p>把下载好的 cuDNN 的 zip 解压后，把 bin、include、lib 三个文件夹内的文件拷贝到 CUDA 9.0 的目录下的对应文件中即可。</p>
<p>CUDA 的默认路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\</span><br></pre></td></tr></table></figure>
<p>然后开始配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0</span><br></pre></td></tr></table></figure>
<h2 id="二、创建虚拟环境"><a href="#二、创建虚拟环境" class="headerlink" title="二、创建虚拟环境"></a>二、创建虚拟环境</h2><p>这里还是比较建议新创建一个虚拟环境，免得安装好的 tensorflow-gpu 跟原环境中的某些包冲突。</p>
<h3 id="1-打开Anaconda-Prompt"><a href="#1-打开Anaconda-Prompt" class="headerlink" title="1.打开Anaconda Prompt"></a>1.打开Anaconda Prompt</h3><p><img src="https://img2018.cnblogs.com/blog/1413964/201812/1413964-20181203205802914-999752375.png" alt="img"></p>
<h3 id="2-创建虚拟环境"><a href="#2-创建虚拟环境" class="headerlink" title="2.创建虚拟环境"></a>2.创建虚拟环境</h3><p>键入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name tensorflow-gpu python=3.6.1</span><br></pre></td></tr></table></figure>
<h3 id="3-启动虚拟环境"><a href="#3-启动虚拟环境" class="headerlink" title="3.启动虚拟环境"></a>3.启动虚拟环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate tensorflow-gpu</span><br></pre></td></tr></table></figure>
<p><img src="https://img2018.cnblogs.com/blog/1413964/201812/1413964-20181203210228822-1233952696.png" alt="img"></p>
<h2 id="三、安装tensorflow-gpu"><a href="#三、安装tensorflow-gpu" class="headerlink" title="三、安装tensorflow-gpu"></a>三、安装tensorflow-gpu</h2><h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h3><p>两种方法</p>
<ol>
<li><p>pip install –upgrade tensorflow-gpu</p>
</li>
<li><p>下载 tensorflow-gpu 的离线安装包，找到下载好的whl路径，然后键入 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install c:\...\tensorflow_gpu-xxxx.whl</span><br></pre></td></tr></table></figure>
<p><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="noopener">下载地址</a></p>
</li>
</ol>
<h3 id="2-测试"><a href="#2-测试" class="headerlink" title="2.测试"></a>2.测试</h3><p>输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python</span><br></pre></td></tr></table></figure>
<p>然后再输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br></pre></td></tr></table></figure>
<p>如果没报错，就表示安装成功了。</p>
<p>然后，再来段 tensorflow 的 hello world</p>
<p><a href="javascript:void(0" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>;)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">tf.enable_eager_execution()</span><br><span class="line"></span><br><span class="line">a = tf.constant(1)</span><br><span class="line">b = tf.constant(1)</span><br><span class="line">c = tf.add(a, b)  </span><br><span class="line"></span><br><span class="line">print(c)</span><br></pre></td></tr></table></figure>
<p><a href="javascript:void(0" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>;)</p>
<p><img src="https://img2018.cnblogs.com/blog/1413964/201812/1413964-20181203211520084-903694026.png" alt="img"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，我们的 tensorflow-gpu 就装好了，接下来就开始 tensorflow 的学习之旅吧。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/19/机器学习5-决策树（部分/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/19/机器学习5-决策树（部分/" itemprop="url">机器学习5  决策树（部分)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-19T01:00:39+08:00">
                2019-03-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>​                               </p>
<h1 id="机器学习5（决策树）"><a href="#机器学习5（决策树）" class="headerlink" title="机器学习5（决策树）"></a>机器学习5（决策树<1>）</1></h1><h5 id="1-决策树"><a href="#1-决策树" class="headerlink" title="1.决策树"></a>1.决策树</h5><p>决策树为树结构，节点时决策结果，每隔叶节点存放一个类别，在每个节点的数个输出中，每个输出都代表特征属性在某个值域上的输出。</p>
<h5 id="2-构成"><a href="#2-构成" class="headerlink" title="2.构成"></a>2.构成</h5><p>构造决策树最关键时在节点进行分支的时候，所分出的各个分支要尽可能的纯。典型的有三种算法：ID3算法使用信息增益作为不纯度，C4.5算法使用信息增益律作为不纯度，CART算法使用基尼系数作为不纯度。</p>
<h5 id="3-信息增益，信息增益率，基尼系数"><a href="#3-信息增益，信息增益率，基尼系数" class="headerlink" title="3. 信息增益，信息增益率，基尼系数"></a>3. 信息增益，信息增益率，基尼系数</h5><p>信息增益越大，属性纯度越高，信息增益率是信息增益处以数目的平均值，基尼指数反应的是随机抽取两个样本，其类别不一致的概率，因此Gini(D)越小，数据集D的纯度越高。</p>
<h5 id="4-剪枝（防止过拟合）"><a href="#4-剪枝（防止过拟合）" class="headerlink" title="4. 剪枝（防止过拟合）"></a>4. 剪枝（防止过拟合）</h5><p>优点：计算复杂度不高，输出结果容易理解，对中间值的缺失不敏感，可以处理不相关特征数据<br>缺点：可能产生过拟合问题<br>适用数据类型：数值型和标称型</p>
<h6 id="3-1-预剪枝"><a href="#3-1-预剪枝" class="headerlink" title="3.1 预剪枝"></a>3.1 预剪枝</h6><pre><code>预剪枝对划分前后的泛化性能进行估计，若对某一节点划分后验证集的精度下降，则禁止划分该节点。预剪枝使得决策树的很多分支没有展开，不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高。预剪枝基于“贪心”的本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。
停止分类的条件：
</code></pre><p>(1) 如果节点中所有观测属于一类；<br>(2) 如果节点中所有观测的属性取值一致；<br>(3) 如果树的深度达到设定的阈值；<br>(4) 如果该节点所含观测值小于设定的父节点应含观测数的阈值；<br>(5) 如果该节点的子节点所含观测数将小于设定的阈值；<br>(6) 如果没有属性能满足设定的分裂准则的阈值。</p>
<h6 id="3-2-后剪枝"><a href="#3-2-后剪枝" class="headerlink" title="3.2 后剪枝"></a>3.2 后剪枝</h6><pre><code>后剪枝先从训练集生成一棵完整决策树，对每个节点，若将该节点对应的子树替换为叶节点后，验证集精度提升，则进行剪枝。后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树，但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶节点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。
后剪枝的方法：
</code></pre><p>(1) Reduced-Error Pruning (REP)：删除以此节点为根的子树使其成为叶节点，赋予该节点关联的训练数据的最常见分类，当修剪后的树对于验证集合的性能不会比原来的树差时，才真正删除该节点。<br>(2) Pessimistic Error Pruning (PEP)：计算某节点的误差，计算该节点的叶节点误差之和，当其误差小于等于叶节点误差之和加一个标准差时，则修建该节点。<br>(3) CCP：给基尼指数加上惩罚项，此时树的层次越深，基尼指数的惩罚项越大。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/18/应用实例/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/18/应用实例/" itemprop="url">应用实例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-18T18:57:57+08:00">
                2019-03-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="海量数据中的商品推荐"><a href="#海量数据中的商品推荐" class="headerlink" title="海量数据中的商品推荐"></a>海量数据中的商品推荐</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from collections import defaultdict</span><br><span class="line">from operator import itemgetter</span><br><span class="line"></span><br><span class="line">dataset_filename=&quot;C:\Python数据挖掘入门与实践代码和数据集\Code_REWRITE\Chapter 1&quot;</span><br><span class="line">X=np.loadtxt(dataset_filename+r&quot;\affinity_dataset.txt&quot;)</span><br><span class="line">#print(X)</span><br><span class="line">v=defaultdict(int)</span><br><span class="line">i=defaultdict(int)</span><br><span class="line">n=defaultdict(int)</span><br><span class="line"></span><br><span class="line">for sample in X:</span><br><span class="line">    for permiss in range(4):</span><br><span class="line">        if sample[permiss]==0:</span><br><span class="line">            continue</span><br><span class="line">        n[permiss]+=1</span><br><span class="line">        for c in range(4):</span><br><span class="line">            if permiss==c:</span><br><span class="line">                continue</span><br><span class="line">            if sample[c]==1:</span><br><span class="line">                v[(permiss,c)]+=1#两者均为1时加一</span><br><span class="line">            else:</span><br><span class="line">                i[(permiss,c)]+=1#两者不同时为1</span><br><span class="line"></span><br><span class="line">support=v</span><br><span class="line">#permiss=1</span><br><span class="line">#c=3</span><br><span class="line">#print(&quot; -Support:&#123;0&#125;&quot;.format(support[(permiss,c)]))</span><br><span class="line">confidence=defaultdict(float)</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">for permiss,c in v.keys():</span><br><span class="line">    rule=(permiss,c)</span><br><span class="line">    confidence[rule]=v[rule]/n[permiss]</span><br><span class="line">    print(confidence[rule])</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">def print_rule(permiss,c,support,confidence,features):</span><br><span class="line">    permiss_name=features[permiss]</span><br><span class="line">    c_name=features[c]</span><br><span class="line">    print(&quot;Rule if a people buy &#123;0&#125; they will also buy &#123;1&#125;&quot;.format(permiss_name,c_name))</span><br><span class="line"></span><br><span class="line">    #s输出置信度</span><br><span class="line">    #输出支持度</span><br><span class="line">    print(&quot;  -Support: &#123;0&#125;&quot;.format(support[(permiss,c)]))</span><br><span class="line">    print(&quot;  -Confidence&quot;.format(confidence[(permiss,c)]))</span><br><span class="line">##排序找出最佳规则</span><br><span class="line"></span><br><span class="line">print(support)#内涵键值对</span><br><span class="line">sorted_support=sorted(support.items(),key=itemgetter(1),reverse=True)</span><br><span class="line">#输出支持度最高的五个规则</span><br><span class="line">for index in range(5):</span><br><span class="line">    print(&quot; Rule #&#123;0&#125;&quot;.format(index+1))</span><br><span class="line">    permiss,c=sorted_support[index][0]</span><br><span class="line">    print_rule(permiss,c,support,confidence,features)</span><br><span class="line">    </span><br><span class="line">#输出置信度最高的规则</span><br><span class="line">sorted_confidence=sorted(support.items(),key=itemgetter(1),reverse=True)</span><br><span class="line">for index in sorted_confidence:</span><br><span class="line">    permiss,c=sorted_confidence[index][0]</span><br><span class="line">    print_rule(permiss,c,support,confidence,features)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/18/java聊天室的实现/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yu-shui">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yu-shui">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/18/java聊天室的实现/" itemprop="url">java聊天室的实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-18T10:01:45+08:00">
                2019-03-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="java-聊天室的实现"><a href="#java-聊天室的实现" class="headerlink" title="java 聊天室的实现"></a>java 聊天室的实现</h1><h4 id="1-部分代码"><a href="#1-部分代码" class="headerlink" title="1.部分代码"></a>1.部分代码</h4><p>Sqlserver类是一个自己设定的数据存储类，与登录界面共同作用，记录当前在线的人数，以及实现一些必备的功能函数，如返回在线用户的列表，删除用户等。<br><figure class="highlight plain"><figcaption><span>projectcenter;</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line">import java.util.Map.Entry;</span><br><span class="line">import java.util.Set;</span><br><span class="line"></span><br><span class="line">//用户数据库</span><br><span class="line">public class SqlServer &#123;</span><br><span class="line">   private static Map&lt;String,UserInfor&gt;SQL=new HashMap();</span><br><span class="line">   </span><br><span class="line">   //判断输入账号是否存在</span><br><span class="line">    public static boolean CheckUser(String name) &#123;</span><br><span class="line">    	if(SQL.containsKey(name)) &#123;</span><br><span class="line">    		return true;</span><br><span class="line">    	&#125;</span><br><span class="line">    	//System.out.println(&quot;不存在此用户：&quot;+name);</span><br><span class="line">    	return false;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //检查账号密码是否输入正确</span><br><span class="line">    public static boolean CheckPassword(String name,String Password) &#123;</span><br><span class="line">    	if(SQL.get(name).Check(Password)) &#123;</span><br><span class="line">    		return true;</span><br><span class="line">    	&#125;else &#123;</span><br><span class="line">    		return false;</span><br><span class="line">    	&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //返回对象数组</span><br><span class="line">    public static Map&lt;String, UserInfor&gt; Getusers() &#123;</span><br><span class="line">    	return SQL;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    //返回key1值对应的对象</span><br><span class="line">    public UserInfor returnUser(String name) &#123;</span><br><span class="line">    	return SQL.get(name);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    //返回用户姓名列表</span><br><span class="line">    public String[] Groupusername() &#123;</span><br><span class="line">    	</span><br><span class="line">    	Object[] key =  SQL.keySet().toArray();    </span><br><span class="line">    	Arrays.sort(key); </span><br><span class="line">    	int l=key.length;</span><br><span class="line">    	String username[]=new String[l];</span><br><span class="line">  </span><br><span class="line">    	</span><br><span class="line">    	for(int i=0;i&lt;key.length;i++) &#123;</span><br><span class="line">    		username[i]=key[i].toString();</span><br><span class="line">    		//System.out.println(key[i].toString());</span><br><span class="line">    	&#125;</span><br><span class="line">    	</span><br><span class="line">    	</span><br><span class="line">        return username;</span><br><span class="line">    &#125;</span><br><span class="line">    	</span><br><span class="line">    //创建用户</span><br><span class="line">    public int BuildNewUser(String name,String password) &#123;</span><br><span class="line">    	if(SQL.containsKey(name)) &#123;</span><br><span class="line">    		//System.out.println(&quot;该用户名已存在!请重新输入&quot;);</span><br><span class="line">    		return 0;</span><br><span class="line">    	   &#125;else &#123;</span><br><span class="line">    		   UserInfor u=new UserInfor();</span><br><span class="line">    		   u.SetName(name);</span><br><span class="line">    		   u.SetPwd(password);</span><br><span class="line">    		   System.out.println(&quot;新用户密码为：&quot;+password);</span><br><span class="line">    		   this.SQL.put(name,u);</span><br><span class="line">    		   return 1;</span><br><span class="line">    	   &#125;</span><br><span class="line">    	</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    //遍历打印Map中的键值对</span><br><span class="line">    public static void ShowMap()&#123;</span><br><span class="line">        for(Map.Entry&lt;String, UserInfor&gt; entry: SQL.entrySet())&#123;</span><br><span class="line">            System.out.println(entry.getKey()+&quot;=&quot;+entry.getValue().toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //删除用户</span><br><span class="line">    public static void DeleteUser(String name) &#123;</span><br><span class="line">    	SQL.get(name).SetOnline2();</span><br><span class="line">    </span><br><span class="line">    	</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //返回在线的用户id列表</span><br><span class="line">    public String[] WhoisOnline() &#123;</span><br><span class="line">    	</span><br><span class="line">    	Object[] key =  SQL.keySet().toArray();    </span><br><span class="line">    	Arrays.sort(key); </span><br><span class="line">    	int l=key.length;</span><br><span class="line">    	String username[]=new String[l];</span><br><span class="line">    	for(int i=0;i&lt;key.length;i++) &#123;</span><br><span class="line">            if(SQL.get(key[i].toString()).getOnline()) &#123;//如果在线则加入数组</span><br><span class="line">    		username[i]=key[i].toString();</span><br><span class="line">           &#125;</span><br><span class="line">    	&#125;</span><br><span class="line">    	return username;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //返回不在线用户列表</span><br><span class="line">    public String[] WHoisnotOnline() &#123;</span><br><span class="line">    	Object[] key =  SQL.keySet().toArray();    </span><br><span class="line">    	Arrays.sort(key); </span><br><span class="line">    	int l=key.length;</span><br><span class="line">    	String username[]=new String[l];</span><br><span class="line">    	for(int i=0;i&lt;key.length;i++) &#123;</span><br><span class="line">            if(!SQL.get(key[i].toString()).getOnline()) &#123;//如果不在线则加入数组</span><br><span class="line">    		username[i]=key[i].toString();</span><br><span class="line">           &#125;</span><br><span class="line">    	&#125;</span><br><span class="line">    	return username;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //系统先建立十个用户</span><br><span class="line">    static&#123;</span><br><span class="line">    	for (int i=0;i&lt;10;i++) &#123;</span><br><span class="line">    		UserInfor u=new UserInfor();</span><br><span class="line">    		u.SetName(String.valueOf(i+1));//用户名即是索引</span><br><span class="line">    		u.SetPwd(&quot;123456&quot;);</span><br><span class="line">    		SQL.put(u.get_name(),u);</span><br><span class="line">    	&#125;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来是用户界面类，与BuildCheck类相连接每当用户实现了登录窗口的检测，则新建一个用户类对象Client,用户类中包含了界面的实现和socket消息的发送和接受，以信息的开头辨别信息的种类，若为一号信息则是私聊信息，则再在BufferedReader中读取私聊信息并显示在私聊界面上，二号信息指代群信息。在界面设计时，应当有好友列表上下线下线的的刷新。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">public class Client extends Thread&#123;/部分代码</span><br><span class="line">	</span><br><span class="line">		//监听事件的添加</span><br><span class="line">		send.addActionListener(new ActionListener() &#123;//发送私聊消息</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public void actionPerformed(ActionEvent arg0) &#123;</span><br><span class="line">				// TODO Auto-generated method stub</span><br><span class="line">			   WriterMess(&quot;1&quot;);//表示是私聊信息</span><br><span class="line">         	   WriterMess(selected);//私聊用户号</span><br><span class="line">         	   String mess=textfield.getText();</span><br><span class="line">         	   WriterMess(mess);//私聊信息</span><br><span class="line">         	   area.append(&quot;自己：&quot;+mess+&quot;\n&quot;);</span><br><span class="line">         	  if(mess.equals(&quot;bye&quot;)) &#123;//设置用户下线</span><br><span class="line">					WriterMess(&quot;3&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">		&#125;);</span><br><span class="line">		</span><br><span class="line">		send2.addActionListener(new ActionListener() &#123;//实现群聊功能</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public void actionPerformed(ActionEvent arg0) &#123;</span><br><span class="line">				// TODO Auto-generated method stub</span><br><span class="line">				try &#123;</span><br><span class="line">					WriterMess(&quot;2&quot;);</span><br><span class="line">					String gets=textfield2.getText();				</span><br><span class="line">					WriterMess(gets);</span><br><span class="line">					if(gets.equals(&quot;bye&quot;)) &#123;//设置用户下线</span><br><span class="line">						WriterMess(&quot;3&quot;);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125; catch(Exception e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">					</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">		&#125;);</span><br><span class="line">		</span><br><span class="line">		 //JList点击事件的添加</span><br><span class="line">		list1.addMouseListener(new MouseAdapter() &#123;</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public void mouseClicked(MouseEvent arg0) &#123;</span><br><span class="line">				// TODO Auto-generated method stub</span><br><span class="line">				String select=(String) list1.getSelectedValue();</span><br><span class="line">            	if(!select.equals(userinfor.get_name())) &#123;//不能对自己进行私聊</span><br><span class="line">                   area.append(&quot;	================================================\n&quot;);</span><br><span class="line">            	   area.append(&quot;	===你选择&quot;+select+&quot;号在线客户进行私聊===\n&quot;);</span><br><span class="line">            	   </span><br><span class="line">            	   selected=select;</span><br><span class="line"></span><br><span class="line">            	&#125;else &#123;</span><br><span class="line">            		area.append(&quot;    	============您不能选择自己进行私聊!===========\n&quot;);</span><br><span class="line">            	&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">		&#125;);</span><br><span class="line">		</span><br><span class="line">		list2.addMouseListener(new MouseAdapter() &#123;</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public void mouseClicked(MouseEvent e) &#123;</span><br><span class="line">				// TODO Auto-generated method stub</span><br><span class="line">				area.append(&quot;=================当前用户不在线！=============\n&quot;);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		</span><br><span class="line">		&#125;);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	public void ShashSelf() &#123;</span><br><span class="line">		this.use.updateUI();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	public void CloseSelf() &#123;//将自己关闭</span><br><span class="line">		try &#123;</span><br><span class="line">			socket.close();</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	public void ReadMess() &#123;</span><br><span class="line">		 //读取服务器返回的消息</span><br><span class="line">		try &#123;</span><br><span class="line">			BufferedReader br = new BufferedReader(new InputStreamReader(in));</span><br><span class="line">	        String mess1 = br.readLine();</span><br><span class="line">		while(true) &#123;</span><br><span class="line">        </span><br><span class="line">        //私聊消息</span><br><span class="line">        </span><br><span class="line">        System.out.println(&quot;mess1：&quot;+mess1);</span><br><span class="line">        System.out.println(&quot;****************************************&quot;);</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        	</span><br><span class="line">        /*while(mess1.equals(&quot;4&quot;)) &#123;//刷新</span><br><span class="line">        		this.use.revalidate();</span><br><span class="line">        		mess1=br.readLine();</span><br><span class="line">        		 System.out.println(&quot;mess1：&quot;+mess1);</span><br><span class="line">        	        System.out.println(&quot;****************************************&quot;);</span><br><span class="line">        	&#125;*/</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        while(mess1.equals(&quot;1&quot;)) &#123;//私聊</span><br><span class="line">        	System.out.println(&quot;*********收到信息**************\n&quot;);</span><br><span class="line">        	String mess2=br.readLine();//用户号</span><br><span class="line">        	System.out.println(&quot;发信息的用户号为&quot;+mess2);</span><br><span class="line">        	String mess3=br.readLine();//信息</span><br><span class="line">        	System.out.println(&quot;私信为&quot;+mess3);</span><br><span class="line">        	area.append(&quot;客户&quot;+mess2+&quot;对您私聊说:  &quot;);</span><br><span class="line">        	area.append(mess3+&quot;\n&quot;);</span><br><span class="line">        	</span><br><span class="line">        	mess1=br.readLine();//刷新mess1</span><br><span class="line">        	 System.out.println(&quot;mess1：&quot;+mess1);</span><br><span class="line">             System.out.println(&quot;****************************************&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        //群聊消息</span><br><span class="line">        while((mess1.equals(&quot;2&quot;))) &#123;</span><br><span class="line">        	String mess2=br.readLine();</span><br><span class="line">        	if(mess2.equals(&quot;4&quot;)) &#123;</span><br><span class="line">        		//this.use.revalidate();</span><br><span class="line">        		//use.repaint();</span><br><span class="line">        		String WhoisOnline[]=SQL.WhoisOnline();</span><br><span class="line">        		list1.setListData(WhoisOnline);</span><br><span class="line">        		String WhoisNotOnline[]=SQL.WHoisnotOnline();</span><br><span class="line">        		list2.setListData(WhoisNotOnline);</span><br><span class="line">        		System.out.println(&quot;2中收到四号消息&quot;);</span><br><span class="line">        		mess1=br.readLine();</span><br><span class="line">        	&#125;else &#123;</span><br><span class="line">        	area2.append(mess2+&quot;\n&quot;);</span><br><span class="line">        	mess1=br.readLine();</span><br><span class="line">        	 System.out.println(&quot;mess1：&quot;+mess1);</span><br><span class="line">             System.out.println(&quot;****************************************&quot;);</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">       while((mess1.equals(&quot;3&quot;))) &#123;//终止</span><br><span class="line">        	br.close();</span><br><span class="line">        	bw.close();</span><br><span class="line">        	in.close();</span><br><span class="line">        	out.close();</span><br><span class="line">        	this.socket.close();</span><br><span class="line">        	mess1=&quot;&quot;;</span><br><span class="line">        	this.runnning=false;</span><br><span class="line">        	SqlServer.DeleteUser(this.userinfor.get_name());</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        if(!this.runnning) &#123;</span><br><span class="line">        	break;</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">        </span><br><span class="line">	     &#125;catch(Exception e) &#123;</span><br><span class="line">	    	 e.printStackTrace();</span><br><span class="line">	   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>自定义一个ChatList类，用于管理在线聊天的与服务器相连的线程对象，在这个类中实现了向所有的在线Client发送消息的函数功能，也实现了删除在线ThreadForChat对象，在线的ThreadForChat是一个与Server服务器相关联的类，每当有一个Client与Server相连接，Server就创造一个ThreadForChat对象与之相连实现通信，在Server类中的强制删除功能既是删除对应的ThreadForChat类并向对应的Client对象发出下线的消息,实现强制下线。CLass   BuildCheck是登录窗口，每当用户输入账号和验证密码并且检验正确时，就new一个Client对象。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Yu-shui</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Yu-shui" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yu-shui</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count"></span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
